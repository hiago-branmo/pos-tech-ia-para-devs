# Recomenda√ß√µes de Modelagem - Dataset de Diabetes

## Problema

**Tipo:** Classifica√ß√£o Bin√°ria Supervisionada
**Vari√°vel Alvo:** `diagnosed_diabetes` (0 = Sem diabetes, 1 = Com diabetes)
**Dataset:** ~100.000 exemplos, 31 vari√°veis (7 categ√≥ricas + 23 num√©ricas + 1 target)

---

## 1. Features: O que Usar e o que Remover

### ‚ùå REMOVER OBRIGATORIAMENTE

#### 1.1 `diabetes_stage`
**Motivo:** DATA LEAKAGE (vazamento de dados)
- Esta coluna indica o est√°gio do diabetes (Type 1, Type 2, Pre-Diabetes, Gestational, No Diabetes)
- √â uma consequ√™ncia DIRETA do diagn√≥stico
- Usar esta vari√°vel √© como "trapacear" - o modelo ter√° 100% de acur√°cia mas n√£o funcionar√° em produ√ß√£o
- **Analogia:** √â como prever se algu√©m passou no vestibular usando a informa√ß√£o "est√° matriculado na universidade"

#### 1.2 `diabetes_risk_score`
**Motivo:** REDUND√ÇNCIA / MULTICOLINEARIDADE
- Este score provavelmente √© calculado a partir de outras vari√°veis do dataset
- Usar o score + suas componentes = multicolinearidade severa
- **Op√ß√£o A:** Remover completamente (recomendado)
- **Op√ß√£o B:** Usar APENAS o score e remover algumas vari√°veis cl√≠nicas

### ‚ö†Ô∏è CONSIDERAR REMOVER (Multicolinearidade)

#### 1.3 Vari√°veis Glic√™micas (escolher 1 ou 2)
- `glucose_fasting` (glicose em jejum)
- `glucose_postprandial` (glicose p√≥s-refei√ß√£o)
- `hba1c` (hemoglobina glicada - m√©dia de 2-3 meses)

**Recomenda√ß√£o:** Manter apenas `hba1c` (marcador gold standard)
- HbA1c √© o crit√©rio diagn√≥stico oficial (‚â• 6.5% = diabetes)
- J√° reflete m√©dia das glicemias ao longo do tempo
- Remover as duas glicemias pontuais reduz multicolinearidade

**OU:** Criar feature composta
```python
df['glucose_avg'] = (df['glucose_fasting'] + df['glucose_postprandial']) / 2
# E remover glucose_fasting e glucose_postprandial
```

#### 1.4 Colesterol Total vs HDL + LDL
- `cholesterol_total` √© aproximadamente = HDL + LDL + triglicer√≠deos/5

**Recomenda√ß√£o:** Remover `cholesterol_total` e manter:
- `hdl_cholesterol` (colesterol "bom")
- `ldl_cholesterol` (colesterol "ruim")
- `triglycerides`

### ‚úÖ FEATURES IMPORTANTES A MANTER

#### Marcadores Cl√≠nicos Diretos
- ‚úÖ `hba1c` - Gold standard para diabetes
- ‚úÖ `insulin_level` - Resist√™ncia insul√≠nica
- ‚úÖ `bmi` - Obesidade (fator de risco principal)
- ‚úÖ `waist_to_hip_ratio` - Obesidade central

#### Fatores de Risco Cardiovasculares
- ‚úÖ `systolic_bp` e `diastolic_bp` - Hipertens√£o
- ‚úÖ `hdl_cholesterol`, `ldl_cholesterol`, `triglycerides`

#### Estilo de Vida
- ‚úÖ `physical_activity_minutes_per_week` - Sedentarismo
- ‚úÖ `diet_score` - Qualidade alimentar
- ‚úÖ `sleep_hours_per_day`
- ‚úÖ `alcohol_consumption_per_week`
- ‚úÖ `screen_time_hours_per_day`
- ‚úÖ `smoking_status` (categ√≥rica)

#### Demogr√°ficas e Hist√≥rico
- ‚úÖ `age` - Idade
- ‚úÖ `gender` - G√™nero (categ√≥rica)
- ‚úÖ `family_history_diabetes` - Gen√©tica
- ‚úÖ `hypertension_history` - Comorbidade
- ‚úÖ `cardiovascular_history` - Comorbidade

#### Socioecon√¥micas (opcional - testar import√¢ncia)
- ‚ö†Ô∏è `ethnicity`
- ‚ö†Ô∏è `education_level`
- ‚ö†Ô∏è `income_level`
- ‚ö†Ô∏è `employment_status`

**Nota:** Vari√°veis socioecon√¥micas podem ter pouco poder preditivo mas s√£o importantes para an√°lise de equidade/fairness do modelo.

---

## 2. Modelos Recomendados

### ü•á Tier 1: ALTAMENTE RECOMENDADOS

#### 2.1 **Random Forest Classifier**
**Por que usar:**
- ‚úÖ Funciona muito bem com dados tabulares
- ‚úÖ Robusto a outliers e missing values
- ‚úÖ N√£o requer normaliza√ß√£o
- ‚úÖ Feature importance autom√°tica
- ‚úÖ Bom com dados desbalanceados (ajustar class_weight)
- ‚úÖ Baixo risco de overfitting (se n_estimators alto)

**Configura√ß√£o sugerida:**
```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    min_samples_split=10,
    min_samples_leaf=5,
    class_weight='balanced',  # Para dados desbalanceados
    random_state=42,
    n_jobs=-1  # Usar todos os cores
)
```

**Quando usar:**
- Primeira linha de an√°lise
- Quando interpretabilidade moderada √© suficiente
- Quando h√° suspeita de intera√ß√µes n√£o-lineares

---

#### 2.2 **XGBoost / LightGBM / CatBoost**
**Por que usar:**
- ‚úÖ ESTADO DA ARTE para dados tabulares
- ‚úÖ Melhor performance que Random Forest (geralmente)
- ‚úÖ Controle fino de overfitting (early stopping, regulariza√ß√£o)
- ‚úÖ R√°pido e eficiente
- ‚úÖ Feature importance detalhada

**XGBoost - Configura√ß√£o sugerida:**
```python
import xgboost as xgb

model = xgb.XGBClassifier(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.01,
    subsample=0.8,
    colsample_bytree=0.8,
    scale_pos_weight=1,  # Ajustar se desbalanceado
    random_state=42,
    eval_metric='logloss',
    early_stopping_rounds=50  # Parar se n√£o melhorar
)
```

**LightGBM - Mais r√°pido:**
```python
import lightgbm as lgb

model = lgb.LGBMClassifier(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.01,
    num_leaves=31,
    class_weight='balanced',
    random_state=42
)
```

**Quando usar:**
- Quando busca melhor performance poss√≠vel
- Competi√ß√µes (Kaggle-style)
- Produ√ß√£o (deploy em sistemas reais)

---

#### 2.3 **Regress√£o Log√≠stica (com Regulariza√ß√£o)**
**Por que usar:**
- ‚úÖ MELHOR INTERPRETABILIDADE (coeficientes = efeitos)
- ‚úÖ R√°pido para treinar
- ‚úÖ Baseline s√≥lido
- ‚úÖ Probabilidades calibradas
- ‚úÖ Bom para entender rela√ß√µes lineares

**Configura√ß√£o sugerida:**
```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(
    penalty='l2',  # Ridge (ou 'l1' para Lasso)
    C=1.0,  # Inverso da for√ßa de regulariza√ß√£o
    class_weight='balanced',
    max_iter=1000,
    random_state=42,
    solver='lbfgs'
)
```

**Quando usar:**
- Quando INTERPRETABILIDADE √© cr√≠tica (medicina, regulat√≥rio)
- Para entender rela√ß√µes causais
- Como baseline comparativo
- Quando modelo precisa ser explic√°vel a n√£o-t√©cnicos

**‚ö†Ô∏è Requer:**
- Normaliza√ß√£o (StandardScaler) - j√° feito no preprocessing
- Baixa multicolinearidade (remover features correlacionadas)

---

### ü•à Tier 2: BONS COMPLEMENTARES

#### 2.4 **Support Vector Machine (SVM)**
**Por que usar:**
- ‚úÖ Bom com dados de alta dimens√£o
- ‚úÖ Funciona bem com kernel RBF (n√£o-linearidade)

**Configura√ß√£o sugerida:**
```python
from sklearn.svm import SVC

model = SVC(
    kernel='rbf',
    C=1.0,
    gamma='scale',
    class_weight='balanced',
    probability=True,  # Para obter probabilidades
    random_state=42
)
```

**Quando usar:**
- Dataset m√©dio (< 50k exemplos) - SVM √© lento
- Quando h√° separa√ß√£o n√£o-linear clara
- Como modelo complementar em ensemble

**‚ö†Ô∏è Limita√ß√µes:**
- Lento com datasets grandes (100k pode ser problema)
- Menos interpret√°vel que Logistic Regression

---

#### 2.5 **K-Nearest Neighbors (KNN)**
**Por que usar:**
- ‚úÖ Simples e intuitivo
- ‚úÖ N√£o assume distribui√ß√£o dos dados

**Configura√ß√£o sugerida:**
```python
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(
    n_neighbors=11,  # Testar 5, 11, 21
    weights='distance',  # Vizinhos mais pr√≥ximos t√™m mais peso
    metric='minkowski',
    n_jobs=-1
)
```

**Quando usar:**
- Baseline simples
- An√°lise explorat√≥ria

**‚ö†Ô∏è Limita√ß√µes:**
- Lento para predi√ß√£o (100k exemplos)
- Sens√≠vel a features irrelevantes
- "Curse of dimensionality"

---

#### 2.6 **Redes Neurais (MLP)**
**Por que usar:**
- ‚úÖ Captura intera√ß√µes complexas n√£o-lineares
- ‚úÖ Flex√≠vel

**Configura√ß√£o sugerida:**
```python
from sklearn.neural_network import MLPClassifier

model = MLPClassifier(
    hidden_layer_sizes=(100, 50, 25),  # 3 camadas ocultas
    activation='relu',
    solver='adam',
    alpha=0.0001,  # Regulariza√ß√£o L2
    batch_size=256,
    learning_rate_init=0.001,
    max_iter=500,
    early_stopping=True,
    validation_fraction=0.1,
    random_state=42
)
```

**Quando usar:**
- Quando h√° muitas intera√ß√µes n√£o-lineares
- Dataset grande (> 50k exemplos)
- Quando tree-based models n√£o funcionam bem

**‚ö†Ô∏è Limita√ß√µes:**
- Dif√≠cil de interpretar (caixa-preta)
- Requer tuning cuidadoso
- Pode overfittar facilmente

---

### ü•â Tier 3: AN√ÅLISES COMPLEMENTARES

#### 2.7 **Naive Bayes**
**Por que usar:**
- ‚úÖ Extremamente r√°pido
- ‚úÖ Funciona com pouco dado

**Quando usar:**
- Baseline ultra-r√°pido
- Quando dados s√£o realmente "naive" (features independentes)

**‚ö†Ô∏è Limita√ß√µes:**
- Assume independ√™ncia entre features (raramente verdade)
- Performance geralmente inferior

---

#### 2.8 **Decision Tree (√Årvore √∫nica)**
**Por que usar:**
- ‚úÖ M√ÅXIMA INTERPRETABILIDADE (pode visualizar √°rvore)
- ‚úÖ N√£o requer normaliza√ß√£o

**Quando usar:**
- An√°lise explorat√≥ria
- Entender estrutura de decis√£o
- Baseline (Random Forest sempre melhor)

**‚ö†Ô∏è Limita√ß√µes:**
- Alto risco de overfitting
- Inst√°vel (pequenas mudan√ßas nos dados = √°rvore diferente)

---

## 3. Estrat√©gia de Modelagem Recomendada

### Pipeline Sugerido

```
1. BASELINE SIMPLES
   ‚îî‚îÄ Logistic Regression (interpret√°vel, r√°pido)

2. TREE-BASED MODELS
   ‚îî‚îÄ Random Forest (robusto, feature importance)
   ‚îî‚îÄ XGBoost/LightGBM (melhor performance)

3. ENSEMBLE (combinar modelos)
   ‚îî‚îÄ Voting Classifier (RF + XGB + LR)
   ‚îî‚îÄ Stacking (usar predi√ß√µes como features)

4. AN√ÅLISE DE RESULTADOS
   ‚îî‚îÄ Comparar m√©tricas
   ‚îî‚îÄ An√°lise de erros (FP, FN)
   ‚îî‚îÄ Feature importance
   ‚îî‚îÄ SHAP values (explicabilidade)
```

### M√©tricas de Avalia√ß√£o

**Para dataset balanceado (~50/50):**
- ‚úÖ **Accuracy** (acur√°cia geral)
- ‚úÖ **ROC-AUC** (√°rea sob curva ROC)
- ‚úÖ **F1-Score** (m√©dia harm√¥nica de Precision e Recall)

**Se dataset desbalanceado:**
- ‚úÖ **Precision** (de positivos preditos, quantos s√£o reais?)
- ‚úÖ **Recall** (de positivos reais, quantos detectamos?)
- ‚úÖ **PR-AUC** (√°rea sob curva Precision-Recall)
- ‚úÖ **Confusion Matrix** (analisar FP e FN)

**Contexto M√©dico (diabetes):**
- üè• **Recall √© mais importante** (n√£o queremos perder casos de diabetes - Falso Negativo √© pior)
- ‚ö†Ô∏è Mas Precision tamb√©m importa (muitos Falsos Positivos = exames desnecess√°rios, ansiedade)

---

## 4. Feature Selection (Sele√ß√£o de Features)

### M√©todos Recomendados

#### 4.1 Feature Importance (Random Forest / XGBoost)
```python
# Treinar Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Obter import√¢ncias
importances = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

# Selecionar top N features
top_features = importances.head(20)['feature'].tolist()
```

#### 4.2 SelectKBest (Estat√≠stico)
```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(score_func=f_classif, k=20)
X_train_selected = selector.fit_transform(X_train, y_train)
X_test_selected = selector.transform(X_test)
```

#### 4.3 Recursive Feature Elimination (RFE)
```python
from sklearn.feature_selection import RFE

estimator = LogisticRegression()
selector = RFE(estimator, n_features_to_select=20, step=1)
selector.fit(X_train, y_train)
```

#### 4.4 Remo√ß√£o Manual Baseada em Correla√ß√£o
```python
# J√° feito no preprocessing - remover features com |r| > 0.9
```

---

## 5. Lista Final de Features Recomendadas

### Conjunto M√≠nimo (15-20 features) - RECOMENDADO PARA COME√áAR

```python
features_essenciais = [
    # Marcadores cl√≠nicos diretos
    'hba1c',                    # Gold standard diabetes
    'insulin_level',            # Resist√™ncia insul√≠nica
    'bmi',                      # Obesidade
    'waist_to_hip_ratio',       # Obesidade central

    # Cardiovascular
    'systolic_bp',              # Hipertens√£o
    'diastolic_bp',             # Hipertens√£o
    'hdl_cholesterol',          # Colesterol bom
    'ldl_cholesterol',          # Colesterol ruim
    'triglycerides',            # Lip√≠dios

    # Estilo de vida
    'physical_activity_minutes_per_week',  # Sedentarismo
    'diet_score',               # Alimenta√ß√£o
    'age',                      # Idade

    # Hist√≥rico
    'family_history_diabetes',  # Gen√©tica
    'hypertension_history',     # Comorbidade
    'cardiovascular_history',   # Comorbidade

    # Categ√≥ricas (ap√≥s one-hot encoding)
    'gender_*',                 # G√™nero
    'smoking_status_*'          # Tabagismo
]
```

### Conjunto Completo (todas menos as removidas)

```python
features_completas = [
    # Todas as num√©ricas EXCETO:
    # - diabetes_stage (data leakage)
    # - diabetes_risk_score (redundante)
    # - glucose_fasting (redundante com hba1c)
    # - glucose_postprandial (redundante com hba1c)
    # - cholesterol_total (redundante com HDL+LDL)

    # Todas as categ√≥ricas (one-hot encoded) EXCETO:
    # - diabetes_stage
]
```

---

## 6. C√≥digo Exemplo - Pipeline Completo

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import classification_report, confusion_matrix

# Carregar dados pr√©-processados
X_train = pd.read_csv('X_train.csv')
X_test = pd.read_csv('X_test.csv')
y_train = pd.read_csv('y_train.csv').values.ravel()
y_test = pd.read_csv('y_test.csv').values.ravel()

# Remover features problem√°ticas
features_to_drop = [
    'diabetes_risk_score',
    'glucose_fasting',
    'glucose_postprandial',
    'cholesterol_total'
]
X_train = X_train.drop(columns=features_to_drop, errors='ignore')
X_test = X_test.drop(columns=features_to_drop, errors='ignore')

# Remover colunas de diabetes_stage se existirem (one-hot encoded)
diabetes_stage_cols = [col for col in X_train.columns if 'diabetes_stage' in col.lower()]
X_train = X_train.drop(columns=diabetes_stage_cols, errors='ignore')
X_test = X_test.drop(columns=diabetes_stage_cols, errors='ignore')

print(f"Features finais: {X_train.shape[1]}")

# ========================================
# MODELO 1: Logistic Regression (Baseline)
# ========================================
print("\n" + "="*80)
print("MODELO 1: LOGISTIC REGRESSION")
print("="*80)

lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
y_proba_lr = lr.predict_proba(X_test)[:, 1]

print(f"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_lr):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_lr):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_lr):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_proba_lr):.4f}")

# ========================================
# MODELO 2: Random Forest
# ========================================
print("\n" + "="*80)
print("MODELO 2: RANDOM FOREST")
print("="*80)

rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=15,
    min_samples_split=10,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
y_proba_rf = rf.predict_proba(X_test)[:, 1]

print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_proba_rf):.4f}")

# ========================================
# MODELO 3: XGBoost
# ========================================
print("\n" + "="*80)
print("MODELO 3: XGBOOST")
print("="*80)

xgb_model = xgb.XGBClassifier(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.01,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)
y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

print(f"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_xgb):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_xgb):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_xgb):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_proba_xgb):.4f}")

# ========================================
# COMPARA√á√ÉO FINAL
# ========================================
print("\n" + "="*80)
print("COMPARA√á√ÉO DOS MODELOS")
print("="*80)

results = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],
    'Accuracy': [
        accuracy_score(y_test, y_pred_lr),
        accuracy_score(y_test, y_pred_rf),
        accuracy_score(y_test, y_pred_xgb)
    ],
    'F1-Score': [
        f1_score(y_test, y_pred_lr),
        f1_score(y_test, y_pred_rf),
        f1_score(y_test, y_pred_xgb)
    ],
    'ROC-AUC': [
        roc_auc_score(y_test, y_proba_lr),
        roc_auc_score(y_test, y_proba_rf),
        roc_auc_score(y_test, y_proba_xgb)
    ]
})

print(results.to_string(index=False))
```

---

## 7. Resumo Executivo

### Features a USAR (ap√≥s one-hot encoding):
- ‚úÖ Todas as vari√°veis num√©ricas EXCETO: `diabetes_stage`, `diabetes_risk_score`, `glucose_fasting`, `glucose_postprandial`, `cholesterol_total`
- ‚úÖ Todas as vari√°veis categ√≥ricas EXCETO: `diabetes_stage`

### Modelos Recomendados (ordem de prioridade):
1. ü•á **XGBoost/LightGBM** - Melhor performance
2. ü•á **Random Forest** - Robusto e confi√°vel
3. ü•á **Logistic Regression** - Interpret√°vel (baseline)
4. ü•à **SVM** - Complementar
5. ü•à **Neural Network** - Se houver tempo

### M√©tricas Principais:
- üìä **ROC-AUC** (m√©trica principal)
- üìä **F1-Score** (balanceamento Precision/Recall)
- üìä **Recall** (importante em contexto m√©dico)
- üìä **Confusion Matrix** (an√°lise de erros)

### Next Steps:
1. Executar preprocessing.ipynb
2. Criar notebook de modelagem com os 3 modelos principais
3. Comparar resultados
4. Analisar feature importance
5. Tunning de hiperpar√¢metros (Grid Search)
6. Ensemble (combinar modelos)
